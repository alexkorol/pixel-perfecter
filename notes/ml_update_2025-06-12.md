# ML Track Update — 2025-06-12

- Added data augmentation to `GridDataset` (color jitter, autocontrast, blur, lightweight noise) so training samples better resemble diffusion artifacts.
- Replaced the compact CNN with a residual backbone plus squeeze-excite attention and dropout in the regression head.
- Updated the training loop to blend MSE/MAE with sample weights, apply gradient clipping, and fall back gracefully when AMP is unavailable.
- Expanded inference helper to return multiple ranked cell/offset candidates using a confidence heuristic instead of a single rounded guess.
- Next steps: regenerate the manifest with fresh feedback rows, schedule a full GPU training run, and benchmark against the deterministic pipeline.
- Adjusted preprocessing to keep aspect ratio (`ImageOps.pad`) and scale labels alongside the resized image so the model sees consistent geometry; metrics now report in original pixel units by dividing out the per-sample scale.
- Added `ml/heuristics.py` to port the gradient-peak spacing trick from Astropulse’s MIT pixeldetector, and blended the heuristic candidate into inference. Validation analysis (`python -m ml.analyze_predictions`) shows raw model MAE ≈ [2.4, 3.7, 3.9] px and the combined top-k suggestions landing within 1px on ~25% of synthetic validation samples.
